{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys \n",
    "import torch \n",
    "import datetime\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import IPython.display as ipd\n",
    "from argparse import Namespace\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import librosa\n",
    "import argparse\n",
    "import scipy \n",
    "from IPython.display import Audio\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import cm\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __config__ import *\n",
    "import two_step_mask_learning.dnn.models.conv_tasnet_maskregress as mask_tasnet\n",
    "import two_step_mask_learning.dnn.models.simplified_tasnet as simple_tasnet\n",
    "import two_step_mask_learning.dnn.dataset_loader.augmented_mix_dataloader as augmented_dataloader\n",
    "import two_step_mask_learning.dnn.dataset_loader.torch_dataloader as wsjnormpad_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import two_step_mask_learning.dnn.losses.sisdr as sisdr_lib\n",
    "import two_step_mask_learning.dnn.models.adaptive_frontend as adaptive_fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_by\n",
    "def zero_crossings(m):\n",
    "    signs = np.sign(m)\n",
    "    zcs = np.abs(signs[1:,:] - signs[:-1,:]) / 2.\n",
    "    return zcs\n",
    "\n",
    "n_time_samples, n_freqs = enc_basis.T.shape\n",
    "zero_cross_per_col = zero_crossings(enc_basis.T)\n",
    "e = enc_basis.T[:, np.argsort(np.sum(zero_cross_per_col, axis=0))]\n",
    "new_bias = enc_bias[np.argsort(np.sum(zero_cross_per_col, axis=0))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_model_path = '/home/thymios/tn_mask/augmented/ESC50_1.0/'\n",
    "a_mask_model = mask_tasnet.CTN.load_best_model(mask_model_path, 'softmax', 128, 21, 0.)\n",
    "mask_enc = a_mask_model.encoder.conv.weight.detach().cpu().squeeze().numpy().T\n",
    "mask_dec = a_mask_model.decoder.deconv.weight.detach().cpu().squeeze().numpy().T\n",
    "# print the encoder \n",
    "plt.figure(figsize=(20,10))\n",
    "im = plt.imshow(masc_enc, interpolation='nearest')\n",
    "plt.colorbar(im, fraction=0.005)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "im = plt.imshow(mask_dec[:, :mask_dec.shape[-1]//2], interpolation='nearest')\n",
    "plt.colorbar(im, fraction=0.005)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_tasnet_model_path = '/home/thymios/tn_mask/augmented/WSJMIX_0.5_ESC50_0.5/'\n",
    "a_tasnet_model = simple_tasnet.TDCN.load_best_model(\n",
    "    simple_tasnet_model_path, 128, 21)\n",
    "mask_enc = a_tasnet_model.fe[0].weight.detach().cpu().squeeze().numpy().T\n",
    "mask_dec = a_tasnet_model.be.weight.detach().cpu().squeeze().numpy().T\n",
    "# print the encoder \n",
    "plt.figure(figsize=(20,10))\n",
    "im = plt.imshow(mask_enc, interpolation='nearest')\n",
    "plt.colorbar(im, fraction=0.005)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "im = plt.imshow(mask_dec[:, :mask_dec.shape[-1]//2], interpolation='nearest')\n",
    "plt.colorbar(im, fraction=0.005)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to do inference with different loaders\n",
    "n_samples = 2\n",
    "batch_size = 2\n",
    "\n",
    "# wsj_normpad_gen = wsjnormpad_loader.get_data_generators(\n",
    "#             [WSJ_MIX_2_8K_PREPROCESSED_EVAL_P], bs=batch_size,\n",
    "#             n_jobs=4, get_top=[n_samples],\n",
    "#             return_items=['mixture_wav_norm', 'clean_sources_wavs_norm'])[0]\n",
    "\n",
    "these_args = argparse.Namespace(\n",
    "            input_dataset_p=[WSJ_MIX_HIERARCHICAL_P + '/test/', ESC50_HIERARCHICAL_P + '/test/'],\n",
    "            datasets_priors=[0.5, 0.5],\n",
    "            batch_size=batch_size,\n",
    "            n_jobs=4,\n",
    "            n_samples=n_samples,\n",
    "            return_items=['wav'],\n",
    "            fs=8000.,\n",
    "            selected_timelength=4.,\n",
    "            n_sources=2,\n",
    "            max_abs_snr=2.5,\n",
    "            fixed_seed=12\n",
    "        )\n",
    "\n",
    "data_loader = augmented_dataloader.AugmentedOnlineMixingDataset(\n",
    "    **vars(these_args))\n",
    "wsj_half_esc50_gen = augmented_dataloader.get_data_gen_from_loader(data_loader)\n",
    "\n",
    "these_args = argparse.Namespace(\n",
    "            input_dataset_p=[ESC50_HIERARCHICAL_P + '/test/'],\n",
    "            datasets_priors=[1.],\n",
    "            batch_size=batch_size,\n",
    "            n_jobs=4,\n",
    "            n_samples=n_samples,\n",
    "            return_items=['wav'],\n",
    "            fs=8000.,\n",
    "            selected_timelength=4.,\n",
    "            n_sources=2,\n",
    "            max_abs_snr=2.5,\n",
    "            fixed_seed=8\n",
    "        )\n",
    "\n",
    "data_loader = augmented_dataloader.AugmentedOnlineMixingDataset(\n",
    "    **vars(these_args))\n",
    "esc50_gen = augmented_dataloader.get_data_gen_from_loader(data_loader)\n",
    "\n",
    "these_args = argparse.Namespace(\n",
    "            input_dataset_p=[WSJ_MIX_HIERARCHICAL_P + '/test/'],\n",
    "            datasets_priors=[1.],\n",
    "            batch_size=batch_size,\n",
    "            n_jobs=4,\n",
    "            n_samples=n_samples,\n",
    "            return_items=['wav'],\n",
    "            fs=8000.,\n",
    "            selected_timelength=4.,\n",
    "            n_sources=2,\n",
    "            max_abs_snr=2.5,\n",
    "            fixed_seed=8\n",
    "        )\n",
    "\n",
    "data_loader = augmented_dataloader.AugmentedOnlineMixingDataset(\n",
    "    **vars(these_args))\n",
    "wsj_gen = augmented_dataloader.get_data_gen_from_loader(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some good files for showing their latent representations\n",
    "selected_ind = 0\n",
    "for i, (mixture, sources) in enumerate(wsj_half_esc50_gen):\n",
    "    if selected_ind == i:\n",
    "        mix_wav = mixture.squeeze()[0]\n",
    "        s1_wav = sources.squeeze()[0][0]\n",
    "        s2_wav = sources.squeeze()[0][1]\n",
    "        print('Mixture')\n",
    "        ipd.display(Audio(mix_wav, rate=8000))\n",
    "        print('Source 1')\n",
    "        ipd.display(Audio(s1_wav, rate=8000))\n",
    "        print(mix_wav.shape)\n",
    "        print('Source 2')\n",
    "        ipd.display(Audio(s2_wav, rate=8000))\n",
    "        print(s1_wav.shape)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_encoded(mix_encoded, s1_encoded, s2_encoded, exponent=0.003):\n",
    "    plt.figure(figsize=(100,10))\n",
    "    plt.imshow(mix_encoded**exponent, cmap=cm.Greens_r)\n",
    "    plt.title('Mixture encoded', fontsize=40)\n",
    "    plt.show()\n",
    "\n",
    "#     s1_encoded -= np.mean(s1_encoded, axis=1, keepdims=True)\n",
    "#     mix_encoded -= np.mean(mix_encoded, axis=1, keepdims=True)\n",
    "#     s2_encoded -= np.mean(s2_encoded, axis=1, keepdims=True)\n",
    "\n",
    "#     s1_encoded = np.abs(s1_encoded)\n",
    "#     mix_encoded = np.abs(mix_encoded)\n",
    "#     s2_encoded = np.abs(s2_encoded)\n",
    "    \n",
    "    plt.figure(figsize=(100,10))\n",
    "    plt.imshow(s1_encoded**exponent, interpolation='nearest', cmap=cm.Blues_r)\n",
    "    plt.title('Source 1 Mask', fontsize=40)\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(100,10))\n",
    "    plt.imshow(s2_encoded**exponent, interpolation='nearest', cmap=cm.Reds_r)\n",
    "    plt.title('Source 2 Mask', fontsize=40)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(100,10))\n",
    "    plt.imshow(abs(s2_encoded - s1_encoded)**exponent , interpolation='nearest', cmap=cm.Reds_r)\n",
    "    plt.title('Source 2 - Source 1', fontsize=40)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(100,10))\n",
    "    plt.imshow((s1_encoded )**exponent , interpolation='nearest', cmap=cm.Blues_r, alpha=0.9)\n",
    "    plt.imshow((s2_encoded)**exponent , interpolation='nearest', cmap=cm.Reds_r, alpha=0.6)\n",
    "    plt.title('Superposition', fontsize=40)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def better_plot_encoded(mix_encoded, s1_encoded, s2_encoded, exponent=0.003):\n",
    "#     fig, (ax1, ax2, ax3) = plt.subplots(nrows=1, ncols=3)\n",
    "    fig = plt.figure(figsize=(20,10))\n",
    "    ax1 = fig.add_subplot(1, 3, 1)\n",
    "    ax2 = fig.add_subplot(1, 3, 2)\n",
    "    ax3 = fig.add_subplot(1, 3, 3)\n",
    "\n",
    "    title_size = 24\n",
    "    \n",
    "    ax1.set_title('Mixture', fontsize=title_size)\n",
    "    ax2.set_title('Speech', fontsize=title_size)\n",
    "    ax3.set_title('Bird Chirping', fontsize=title_size)\n",
    "    \n",
    "    aspect = 0.00375\n",
    "    ax1.imshow(mix_encoded.squeeze()**exponent, interpolation='none', \n",
    "               cmap=cm.Greens_r, extent=[0,1,0,127], aspect=aspect)\n",
    "    ax1.xaxis.set_visible(False)\n",
    "    ax1.set_ylabel('Encoder Basis Index', fontsize=19)\n",
    "\n",
    "#     ax1.set_yticks(np.arange(mix_encoded.shape[0]))\n",
    "#     ax1.yaxis.set_visible(False)\n",
    "\n",
    "    \n",
    "    ax2.imshow(s1_encoded.squeeze()**exponent, interpolation='none', cmap=cm.Blues_r,\n",
    "              extent=[0,1,0,127], aspect=aspect)\n",
    "    ax2.yaxis.set_visible(False)\n",
    "    ax2.xaxis.set_visible(False)\n",
    "\n",
    "    \n",
    "    ax3.imshow(s2_encoded.squeeze()**exponent, interpolation='none', cmap=cm.Reds_r,\n",
    "              extent=[0,1,0,127], aspect=aspect)\n",
    "    ax3.yaxis.set_visible(False)\n",
    "    ax3.xaxis.set_visible(False)\n",
    "\n",
    "    plt.show()\n",
    "    fig.savefig(\"our_latents.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_model_path = '/home/thymios/tn_mask/augmented/WSJMIX_0.5_ESC50_0.5/'\n",
    "a_mask_model = mask_tasnet.CTN.load_best_model(mask_model_path, 'softmax', 128, 21, 0.)\n",
    "mask_enc = a_mask_model.encoder\n",
    "mask_dec = a_mask_model.decoder\n",
    "\n",
    "enc_basis = mask_enc.conv.weight.squeeze().numpy()\n",
    "enc_bias = mask_enc.conv.bias.squeeze().numpy()\n",
    "\n",
    "e = enc_basis.T[:, np.argsort(np.sum(np.abs(enc_basis.T), axis=0))]\n",
    "new_bias = enc_bias[np.argsort(np.sum(np.abs(enc_basis.T), axis=0))]\n",
    "\n",
    "mask_enc.conv.weight = torch.nn.Parameter(torch.tensor(e.T).unsqueeze(1))\n",
    "mask_enc.conv.bias = torch.nn.Parameter(torch.tensor(new_bias).squeeze())\n",
    "\n",
    "offset = 11000\n",
    "duration = 8000\n",
    "\n",
    "mix_encoded = mask_enc(torch.tensor(mix_wav[offset:offset+duration]).unsqueeze(0).unsqueeze(0)).detach().numpy()\n",
    "s1_encoded = mask_enc(torch.tensor(s1_wav[offset:offset+duration]).unsqueeze(0).unsqueeze(0)).detach().numpy()\n",
    "s2_encoded = mask_enc(torch.tensor(s2_wav[offset:offset+duration]).unsqueeze(0).unsqueeze(0)).detach().numpy()\n",
    "# plot_encoded(mix_encoded.squeeze(), s1_encoded.squeeze(), s2_encoded.squeeze(), exponent=0.1)\n",
    "\n",
    "better_plot_encoded(mix_encoded, s1_encoded, s2_encoded, exponent=0.1)\n",
    "\n",
    "# Measure the sparsity \n",
    "print(\"L1 sparsity\")\n",
    "print(np.abs(s1_encoded - np.mean(s1_encoded, axis=2, keepdims=True)).sum(),\n",
    "      np.abs(s2_encoded - np.mean(s2_encoded, axis=2, keepdims=True)).sum(),\n",
    "      np.abs(mix_encoded - np.mean(mix_encoded, axis=2, keepdims=True)).sum())\n",
    "print(\"L0 sparsity\")\n",
    "print(np.abs(s1_encoded - np.mean(s1_encoded, axis=2, keepdims=True)).sum(),\n",
    "      np.abs(s2_encoded - np.mean(s2_encoded, axis=2, keepdims=True)).sum(),\n",
    "      np.abs(mix_encoded - np.mean(mix_encoded, axis=2, keepdims=True)).sum())\n",
    "print(1. * np.count_nonzero(np.abs(s1_encoded - np.mean(s1_encoded, axis=2, keepdims=True))) / np.prod(s1_encoded.shape))\n",
    "print(1. * np.count_nonzero(np.abs(s2_encoded - np.mean(s2_encoded, axis=2, keepdims=True))) / np.prod(s1_encoded.shape))\n",
    "print(1. * np.count_nonzero(np.abs(mix_encoded - np.mean(mix_encoded, axis=2, keepdims=True))) / np.prod(s1_encoded.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def better_plot_encoded_tasnet(mix_encoded, s1_encoded, s2_encoded, exponent=0.003):\n",
    "#     fig, (ax1, ax2, ax3) = plt.subplots(nrows=1, ncols=3)\n",
    "    fig = plt.figure(figsize=(20,10))\n",
    "    ax1 = fig.add_subplot(1, 3, 1)\n",
    "    ax2 = fig.add_subplot(1, 3, 2)\n",
    "    ax3 = fig.add_subplot(1, 3, 3)\n",
    "\n",
    "#     ax1.set_title('Mixture', fontsize=20)\n",
    "#     ax2.set_title('Speech', fontsize=20)\n",
    "#     ax3.set_title('Toothbrush Sound', fontsize=20)\n",
    "    \n",
    "    aspect = 0.00375\n",
    "    ax1.imshow(mix_encoded.squeeze()**exponent, interpolation='none', \n",
    "               cmap=cm.Greens_r, extent=[0,1,0,127], aspect=aspect)\n",
    "    ax1.set_xlabel('Time (secs)', fontsize=20)\n",
    "    ax1.set_ylabel('Encoder Basis Index', fontsize=19)\n",
    "\n",
    "#     ax1.xaxis.set_visible(False)\n",
    "#     ax1.set_yticks(np.arange(mix_encoded.shape[0]))\n",
    "#     ax1.yaxis.set_visible(False)\n",
    "\n",
    "    \n",
    "    ax2.imshow(s1_encoded.squeeze()**exponent, interpolation='none', cmap=cm.Blues_r,\n",
    "              extent=[0,1,0,127], aspect=aspect)\n",
    "    ax2.yaxis.set_visible(False)\n",
    "    ax2.set_xlabel('Time (secs)', fontsize=20)\n",
    "\n",
    "#     ax2.xaxis.set_visible(False)\n",
    "\n",
    "    \n",
    "    ax3.imshow(s2_encoded.squeeze()**exponent, interpolation='none', cmap=cm.Reds_r,\n",
    "              extent=[0,1,0,127], aspect=aspect)\n",
    "    ax3.yaxis.set_visible(False)\n",
    "#     ax3.xaxis.set_visible(False)\n",
    "    ax3.set_xlabel('Time (secs)', fontsize=20)\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "    fig.savefig(\"tasnet_latents.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the same for the trained tasnet\n",
    "simple_tasnet_model_path = '/home/thymios/tn_mask/augmented/WSJMIX_0.5_ESC50_0.5/'\n",
    "a_tasnet_model = simple_tasnet.TDCN.load_best_model(simple_tasnet_model_path, 128, 21)\n",
    "# mask_enc = a_mask_model.encoder\n",
    "# mask_dec = a_mask_model.decoder\n",
    "\n",
    "enc_basis = a_tasnet_model.fe[0].weight.squeeze().detach().cpu().numpy()\n",
    "enc_bias = a_tasnet_model.fe[0].bias.squeeze().detach().cpu().numpy()\n",
    "\n",
    "e = enc_basis.T[:, np.argsort(np.sum(np.abs(enc_basis.T), axis=0))]\n",
    "new_bias = enc_bias[np.argsort(np.sum(np.abs(enc_basis.T), axis=0))]\n",
    "\n",
    "mask_enc.conv.weight = torch.nn.Parameter(torch.tensor(e.T).unsqueeze(1))\n",
    "mask_enc.conv.bias = torch.nn.Parameter(torch.tensor(new_bias).squeeze())\n",
    "\n",
    "offset = 11000\n",
    "duration = 8000\n",
    "\n",
    "mix_encoded = mask_enc(torch.tensor(mix_wav[offset:offset+duration]).unsqueeze(0).unsqueeze(0)).detach().numpy()\n",
    "s1_encoded = mask_enc(torch.tensor(s1_wav[offset:offset+duration]).unsqueeze(0).unsqueeze(0)).detach().numpy()\n",
    "s2_encoded = mask_enc(torch.tensor(s2_wav[offset:offset+duration]).unsqueeze(0).unsqueeze(0)).detach().numpy()\n",
    "# plot_encoded(mix_encoded.squeeze(), s1_encoded.squeeze(), s2_encoded.squeeze(), exponent=0.1)\n",
    "better_plot_encoded_tasnet(mix_encoded, s1_encoded, s2_encoded, exponent=0.1)\n",
    "\n",
    "# Measure the sparsity \n",
    "print(\"L1 sparsity\")\n",
    "print(np.abs(s1_encoded - np.mean(s1_encoded, axis=2, keepdims=True)).sum(),\n",
    "      np.abs(s2_encoded - np.mean(s2_encoded, axis=2, keepdims=True)).sum(),\n",
    "      np.abs(mix_encoded - np.mean(mix_encoded, axis=2, keepdims=True)).sum())\n",
    "print(\"L0 sparsity\")\n",
    "print(np.abs(s1_encoded - np.mean(s1_encoded, axis=2, keepdims=True)).sum(),\n",
    "      np.abs(s2_encoded - np.mean(s2_encoded, axis=2, keepdims=True)).sum(),\n",
    "      np.abs(mix_encoded - np.mean(mix_encoded, axis=2, keepdims=True)).sum())\n",
    "print(1. * np.count_nonzero(np.abs(s1_encoded - np.mean(s1_encoded, axis=2, keepdims=True))) / np.prod(s1_encoded.shape))\n",
    "print(1. * np.count_nonzero(np.abs(s2_encoded - np.mean(s2_encoded, axis=2, keepdims=True))) / np.prod(s1_encoded.shape))\n",
    "print(1. * np.count_nonzero(np.abs(mix_encoded - np.mean(mix_encoded, axis=2, keepdims=True))) / np.prod(s1_encoded.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on WSJnorm pad\n",
    "n_fft = 256\n",
    "hop_length = int(n_fft / 4.)\n",
    "win_length = n_fft\n",
    "\n",
    "def evaluate_ibm_on_generator(loss_func, generator, generator_name='WSJ'):\n",
    "    acc = []\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(generator, desc='Validation on {}'.format(generator_name)):\n",
    "            m1wavs = data[0].squeeze().detach().numpy()\n",
    "            clean_wavs = data[-1].squeeze().detach().numpy()\n",
    "            \n",
    "            m1 = m1wavs\n",
    "            \n",
    "            s1 = clean_wavs[0]\n",
    "            s2 = clean_wavs[1]\n",
    "            \n",
    "            m1_stft = librosa.core.stft(m1, n_fft=n_fft, hop_length=hop_length, win_length=win_length)\n",
    "            s1_stft = librosa.core.stft(s1, n_fft=n_fft, hop_length=hop_length, win_length=win_length)\n",
    "            s2_stft = librosa.core.stft(s2, n_fft=n_fft, hop_length=hop_length, win_length=win_length)\n",
    "            s1_energy = np.abs(s1_stft)**2\n",
    "            s2_energy = np.abs(s2_stft)**2\n",
    "\n",
    "            irm1_stft = np.abs(s1_stft) / (np.abs(s2_stft) + np.abs(s1_stft) + 10e-9)\n",
    "            irm2_stft = np.abs(s2_stft) / (np.abs(s2_stft) + np.abs(s1_stft) + 10e-9)\n",
    "\n",
    "            s1_pred_stft = m1_stft * irm1_stft\n",
    "            s2_pred_stft = m1_stft * irm2_stft\n",
    "\n",
    "            s1_pred = librosa.core.istft(s1_pred_stft, hop_length=hop_length, win_length=win_length)\n",
    "            s2_pred = librosa.core.istft(s2_pred_stft, hop_length=hop_length, win_length=win_length)\n",
    "\n",
    "            pred_sources = np.stack([s1_pred, s2_pred])\n",
    "            pred_sources = torch.from_numpy(pred_sources)\n",
    "         \n",
    "            l = loss_func(pred_sources.unsqueeze(0), data[-1], initial_mixtures=data[0].unsqueeze(1))\n",
    "            acc += l.tolist()\n",
    "    return acc \n",
    "\n",
    "sisdr_loss = sisdr_lib.PermInvariantSISDR(batch_size=batch_size,\n",
    "                                          n_sources=2,\n",
    "                                          zero_mean=True,\n",
    "                                          backward_loss=False,\n",
    "                                          improvement=True,\n",
    "                                          return_individual_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to estimate IBM for all test sets\n",
    "transfer_generators_dict = {'WSJ': wsj_normpad_gen, 'WSJ.5ESC.5': wsj_half_esc50_gen, 'ESC': esc50_gen}\n",
    "transfer_results_dict = {}\n",
    "\n",
    "for generator_name, generator in transfer_generators_dict.items():\n",
    "    results = evaluate_ibm_on_generator(sisdr_loss, generator, generator_name=generator_name)\n",
    "    results = np.array(results)\n",
    "    transfer_results_dict[generator_name] = {}\n",
    "    transfer_results_dict[generator_name]['mean'] = results.mean()\n",
    "    transfer_results_dict[generator_name]['std'] = results.std()\n",
    "    pprint(transfer_results_dict)\n",
    "pprint(transfer_results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
