{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys \n",
    "current_dir = os.path.dirname(os.path.abspath('__file__'))\n",
    "root_dir = os.path.abspath(os.path.join(current_dir, '../../'))\n",
    "sys.path.append(root_dir)\n",
    "from __config__ import * \n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "from glob2 import glob\n",
    "from scipy.io.wavfile import read as scipy_wavread\n",
    "import time \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(WSJ0_MIX_2_8K_PATH)\n",
    "print(WSJ0_MIX_2_16K_PATH)\n",
    "# def WSJ0Loader(Dataset):\n",
    "#     def __init__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check what is happening with the min max folders \n",
    "\n",
    "def analyze_wsj0mix(dirpath):\n",
    "    \n",
    "    min_dir = os.path.join(dirpath, 'min')\n",
    "    max_dir = os.path.join(dirpath, 'max')\n",
    "    \n",
    "    test_dir_min = os.path.join(min_dir, 'tt')\n",
    "    test_dir_max = os.path.join(max_dir, 'tt')\n",
    "#     create the dic for all mixture keys\n",
    "    \n",
    "    \n",
    "    mixtures_dir = os.path.join(test_dir_min, 'mix')\n",
    "    files = glob(mixtures_dir + '/*.wav')\n",
    "    unique_ids = set([os.path.basename(f) for f in files])\n",
    "    \n",
    "#     check about the files in min and max \n",
    "    folders = ['s1', 's2', 'mix']\n",
    "    for uid in unique_ids: \n",
    "        min_files = [(fo, os.path.join(test_dir_min, fo, uid)) for fo in folders]\n",
    "        min_files = dict([(speaker, scipy_wavread(path)[1]) \n",
    "                          for (speaker, path) in min_files])\n",
    "        \n",
    "        max_files = [(fo, os.path.join(test_dir_max, fo, uid)) for fo in folders]\n",
    "        max_files = dict([(speaker, scipy_wavread(path)[1]) \n",
    "                          for (speaker, path) in max_files])\n",
    "        \n",
    "        max_len = max(max_files['s1'].shape[0], max_files['s2'].shape[0])\n",
    "        min_len = min(min_files['s1'].shape[0], min_files['s2'].shape[0])\n",
    "        \n",
    "        assert(max_files['mix'].shape[0] == max_len)\n",
    "        assert(min_files['mix'].shape[0] == min_len)\n",
    "        \n",
    "        condition = np.allclose(max_files['mix'][:min_len], \n",
    "                                min_files['mix'], atol=10e0)\n",
    "        \n",
    "#         if not condition:\n",
    "#             print(max_files['mix'][:min_len].shape)\n",
    "            \n",
    "#             print(min_files['mix'].shape)\n",
    "#             print(min_len)\n",
    "            \n",
    "#             time=np.linspace(0, min_len, num=min_len)\n",
    "#             print(time.shape)\n",
    "#             plt.figure(3)\n",
    "#             plt.title('Mixture')\n",
    "#             plt.plot(time, max_files['mix'][:min_len], \n",
    "#                      time, min_files['mix'], 'r', alpha=0.6)\n",
    "#             plt.show()\n",
    "            \n",
    "        condition = np.allclose(min_files['mix'], \n",
    "                                min_files['s1']+min_files['s2'], \n",
    "                                atol=10e0)\n",
    "        assert(condition)\n",
    "        \n",
    "        if not condition:\n",
    "            time=np.linspace(0, min_len, num=min_len)\n",
    "            print(time.shape)\n",
    "            plt.figure(3)\n",
    "            plt.title('Mixture')\n",
    "            plt.plot(time, min_files['s1']+min_files['s2'], \n",
    "                     time, min_files['mix'], 'r', alpha=0.3)\n",
    "            plt.show() \n",
    "        \n",
    "    return len(unique_ids)\n",
    "\n",
    "before = time.time()\n",
    "n_files = analyze_wsj0mix(WSJ0_MIX_2_8K_PATH)\n",
    "now = time.time()\n",
    "print(\"Read {} files in {} secs\".format(n_files, now - before))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess WSJ0 mix dataset in order to be in universal format\n",
    "class WSJPytorchDataset(Dataset):\n",
    "    \"\"\"Dataset class for time-domian speech separation.\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 dirpath,\n",
    "                 sample_clip_size=4):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            sample_clip_size: segmental length (default: 4s)\n",
    "        \"\"\"\n",
    "        self.dirpath = dirpath \n",
    "        self.fs = self.infer_sampling_rate(self.dirpath)\n",
    "        print(self.fs)\n",
    "        \n",
    "    @staticmethod \n",
    "    def infer_sampling_rate(self, dirpath)\n",
    "        \n",
    "        print(dirpath)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.retrieve_index)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        utt_id, sample_index = self.retrieve_index[index]\n",
    "        mix_sample = wavread(self.mix_path[utt_id])[0]\n",
    "        s1_sample = wavread(self.s1_path[utt_id])[0]\n",
    "        s2_sample = wavread(self.s2_path[utt_id])[0]\n",
    "        if sample_index == -1:\n",
    "            length = len(mix_sample)\n",
    "            stack_length = self.segment_length - length\n",
    "            mix_stack_sample = mix_sample[: stack_length].reshape(-1, 1)\n",
    "            s1_stack_sample = s1_sample[: stack_length].reshape(-1, 1)\n",
    "            s2_stack_sample = s2_sample[: stack_length].reshape(-1, 1)\n",
    "            mix_clipped_sample = np.concatenate(\n",
    "                    (mix_sample, mix_stack_sample), axis=0)\n",
    "            s1_clipped_sample = np.concatenate(\n",
    "                    (s1_sample, s1_stack_sample), axis=0)\n",
    "            s2_clipped_sample = np.concatenate(\n",
    "                    (s2_sample, s2_stack_sample), axis=0)\n",
    "        else:\n",
    "            end_index = sample_index + self.segment_length\n",
    "            mix_clipped_sample = mix_sample[sample_index : end_index]\n",
    "            s1_clipped_sample = s1_sample[sample_index : end_index]\n",
    "            s2_clipped_sample = s2_sample[sample_index : end_index]\n",
    "        src_clipped_sample = np.stack(\n",
    "            (s1_clipped_sample, s2_clipped_sample), axis=0).squeeze(-1)\n",
    "        sample = {\n",
    "            'mix': mix_clipped_sample.reshape(1, -1),\n",
    "            'src': src_clipped_sample.reshape(2, -1),\n",
    "        }\n",
    "        return sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
